{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A Tool for Evaluating and Analysing the Convenience of Property Location Based on 15-minute City Paradigm**\n",
    "\n",
    "Xianlai Yin, MSc Urban Spatial Science, CASA, UCL\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "***Environment***\n",
    "\n",
    "- ArcGIS Pro\n",
    "  - install threadpoolctl\n",
    "  - update scipy\n",
    "  - update pyarrow\n",
    "\n",
    "***Coordinate Systm***\n",
    "\n",
    "- British National Grid (EPSG:27700)\n",
    "\n",
    "***Input File Require*** *(put all these files in a same folder named \"input\" in workspace)*\n",
    "\n",
    "- pois.shp\n",
    "- landuse.shp\n",
    "- area.shp\n",
    "- meanprice.shp\n",
    "- meanprice_idw.tif\n",
    "- population.tif\n",
    "- walkdistance.csv\n",
    "- areacodelist.csv\n",
    "- census (folder)\n",
    "  - RM200-Sex-By-Single-Year-Of-Age-(Detailed)-2021-lsoa-ONS.csv\n",
    "  - TS004-Country-Of-Birth-2021-lsoa-ONS.csv\n",
    "  - TS016-Length-Of-Residence-2021-lsoa-ONS.csv\n",
    "  - TS017-Household-Size-2021-lsoa-ONS.csv\n",
    "  - TS021-Ethnic-Group-2021-lsoa-ONS.csv\n",
    "  - TS030-Religion-2021-lsoa-ONS.csv\n",
    "  - TS045-Car-Or-Van-Availability-2021-lsoa-ONS.csv\n",
    "  - TS051-Number-Of-Rooms-2021-lsoa-ONS.csv\n",
    "  - TS058-Distance-Travelled-To-Work-2021-lsoa-ONS.csv\n",
    "  - TS066-Economic-Activity-Status-2021-lsoa-ONS.csv\n",
    "\n",
    "\n",
    "***Example Data Area***\n",
    "\n",
    "- Greater London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test parameters\n",
    "#folder=\"D:\\\\UCL_CODE\\\\data\\\\workspace\"\n",
    "#area_type=\"borough\"\n",
    "#with open(f\"{folder}\\\\input\\\\areacodelist.csv\", \"r\", encoding=\"utf-8\") as file:\n",
    "    #header = file.readline()\n",
    "    #areacodes = header.split(\",\").index(\"LAD23CD\")\n",
    "    #for line in file:\n",
    "        #values = line.strip().split(\",\")\n",
    "        #area = values[areacodes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### analysispreparation.py\n",
    "\n",
    "***Parameters***\n",
    "\n",
    "|Name|Data Type|Type|Direction|\n",
    "|---|---|---|---|\n",
    "|folder|Folder|Required|Input|\n",
    "|area|String|Required|Input|\n",
    "|area_type|String|Required|Input|\n",
    "|success|Boolean|Derived|Output|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import\n",
    "import arcpy\n",
    "from arcpy.sa import *\n",
    "from sys import argv\n",
    "import os\n",
    "\n",
    "\n",
    "### input parameter\n",
    "folder=arcpy.GetParameterAsText(0)\n",
    "area=arcpy.GetParameterAsText(1)\n",
    "area_type=arcpy.GetParameterAsText(2)\n",
    "\n",
    "\n",
    "### environment\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.workspace = folder\n",
    "\n",
    "\n",
    "### define functions\n",
    "def datapreparation(folder, area, area_type):\n",
    "    # define the function to find the raw data\n",
    "    def inputraw(folder):\n",
    "        area_raw = f\"{folder}\\\\input\\\\area.shp\"\n",
    "        population_raw = f\"{folder}\\\\input\\\\population.tif\"\n",
    "        pois_raw = f\"{folder}\\\\input\\\\pois.shp\"\n",
    "        roads_raw = f\"{folder}\\\\input\\\\roads.shp\"\n",
    "        landuse_raw = f\"{folder}\\\\input\\\\landuse.shp\"\n",
    "        return area_raw, population_raw, pois_raw, roads_raw, landuse_raw\n",
    "    area_raw, population_raw, pois_raw, roads_raw, landuse_raw = inputraw(folder)\n",
    "    \n",
    "    # define the function to select the data\n",
    "    def dataselect(folder, area, area_type, area_raw, population_raw, pois_raw, roads_raw, landuse_raw, _area_parks=r\"{folder}\\{area}\\{area}_pois.gdb\\{area}_parks\", _area_roads=r\"{folder}\\{area}\\{area}_roads.gdb\\{area}_roads\", _area_population=r\"{folder}\\{area}\\{area}_population.gdb\\{area}_population\"):\n",
    "        # create gdb\n",
    "        _folder_ = f\"{folder}\"\n",
    "        # Process: Create Folder (Create Folder) (management)\n",
    "        _area_folder = arcpy.management.CreateFolder(out_folder_path=_folder_, out_name=f\"{area}\")[0]\n",
    "        # Process: Create File Geodatabase boundaries (Create File Geodatabase) (management)\n",
    "        _area_boundaries_gdb = arcpy.management.CreateFileGDB(out_folder_path=_area_folder, out_name=f\"{area}_boundaries\")[0]\n",
    "        # Process: Create File Geodatabase pois (Create File Geodatabase) (management)\n",
    "        _area_pois_gdb = arcpy.management.CreateFileGDB(out_folder_path=_area_folder, out_name=f\"{area}_pois\")[0]\n",
    "        # Process: Create File Geodatabase others (Create File Geodatabase) (management)\n",
    "        _area_others_gdb = arcpy.management.CreateFileGDB(out_folder_path=_area_folder, out_name=f\"{area}_others\")[0]\n",
    "        # Process: Create File Geodatabase population (Create File Geodatabase) (management)\n",
    "        _area_population_gdb = arcpy.management.CreateFileGDB(out_folder_path=_area_folder, out_name=f\"{area}_population\")[0]\n",
    "        # Process: Create File Geodatabase roads (Create File Geodatabase) (management)\n",
    "        #_area_roads_gdb = arcpy.management.CreateFileGDB(out_folder_path=_area_folder, out_name=f\"{area}_roads\")[0]\n",
    "        \n",
    "        # create areas\n",
    "        # define the function to judge the area type\n",
    "        def boroughorward(area_type):\n",
    "            is_borough = area_type in [\"borough\", \"Borough\", \"LAD\"]\n",
    "            is_ward = not is_borough\n",
    "            return is_borough, is_ward\n",
    "        # Process: If Value Is (If Value Is)\n",
    "        borough, ward = boroughorward(area_type)\n",
    "        # Process: select ward (Feature Class To Feature Class) (conversion)\n",
    "        if ward:\n",
    "            _area_ward = arcpy.conversion.FeatureClassToFeatureClass(in_features=area_raw.__str__().format(**globals()), out_path=_area_boundaries_gdb, out_name=f\"{area}_ward\", where_clause=f\"WD23CD = '{area}'\", field_mapping=\"WD23CD \\\"WD23CD\\\" true true false 9 Text 0 0,First,#,{area_raw},WD23CD,0,9;WD23NM \\\"WD23NM\\\" true true false 53 Text 0 0,First,#,{area_raw},WD23NM,0,53;LAD23CD \\\"LAD23CD\\\" true true false 9 Text 0 0,First,#,{area_raw},LAD23CD,0,9;LAD23NM \\\"LAD23NM\\\" true true false 36 Text 0 0,First,#,{area_raw},LAD23NM,0,36\")[0]\n",
    "            analysis_area = _area_ward\n",
    "        # Process: select borough (Feature Class To Feature Class) (conversion)\n",
    "        if borough:\n",
    "            _area_borough = arcpy.conversion.FeatureClassToFeatureClass(in_features=area_raw.__str__().format(**globals()), out_path=_area_boundaries_gdb, out_name=f\"{area}_borough\", where_clause=f\"LAD23CD = '{area}'\", field_mapping=\"WD23CD \\\"WD23CD\\\" true true false 9 Text 0 0,First,#,{area_raw},WD23CD,0,9;WD23NM \\\"WD23NM\\\" true true false 53 Text 0 0,First,#,{area_raw},WD23NM,0,53;LAD23CD \\\"LAD23CD\\\" true true false 9 Text 0 0,First,#,{area_raw},LAD23CD,0,9;LAD23NM \\\"LAD23NM\\\" true true false 36 Text 0 0,First,#,{area_raw},LAD23NM,0,36\")[0]\n",
    "            analysis_area = _area_borough\n",
    "        # Process: Dissolve (Dissolve) (management)\n",
    "        _area_ = fr\"{folder}\\{area}\\{area}_others.gdb\\{area}_boundary\"\n",
    "        arcpy.management.Dissolve(in_features=analysis_area, out_feature_class=_area_)\n",
    "        # Process: Buffer (Buffer) (analysis)\n",
    "        _area_Buffer = fr\"{folder}\\{area}\\{area}_others.gdb\\{area}_Buffer\"\n",
    "        arcpy.analysis.Buffer(in_features=_area_, out_feature_class=_area_Buffer, buffer_distance_or_field=\"1500 Meters\", line_end_type=\"ROUND\", dissolve_option=\"ALL\")\n",
    "        # Process: Intersect pois (Intersect) (analysis)\n",
    "        pois_area_ = fr\"{folder}\\{area}\\{area}_others.gdb\\pois_{area}\"\n",
    "        arcpy.analysis.Intersect(in_features=[[_area_Buffer, \"\"], [pois_raw, \"\"]], out_feature_class=pois_area_, join_attributes=\"NO_FID\")\n",
    "        \n",
    "        # pois\n",
    "        # Process: create health (Feature Class To Feature Class) (conversion)\n",
    "        _area_health = arcpy.conversion.FeatureClassToFeatureClass(in_features=pois_area_, out_path=_area_pois_gdb, out_name=f\"{area}_health\", where_clause=\"code >= 2101 And code <= 2121 Or code = 2013\", field_mapping=\"code \\\"code\\\" true true false 4 Short 0 4,First,#,{pois_raw},code,-1,-1;fclass \\\"fclass\\\" true true false 28 Text 0 0,First,#,{pois_raw},fclass,0,28\")[0]\n",
    "        # Process: create leisure (Feature Class To Feature Class) (conversion)\n",
    "        _area_leisure = arcpy.conversion.FeatureClassToFeatureClass(in_features=pois_area_, out_path=_area_pois_gdb, out_name=f\"{area}_leisure\", where_clause=\"code >= 2201 And code <= 2203 Or code = 2721 Or code = 2722 Or code = 2725 Or code = 2743 Or code = 2744\", field_mapping=\"code \\\"code\\\" true true false 4 Short 0 4,First,#,{pois_raw},code,-1,-1;fclass \\\"fclass\\\" true true false 28 Text 0 0,First,#,{pois_raw},fclass,0,28\")[0]\n",
    "        # Process: create sports (Feature Class To Feature Class) (conversion)\n",
    "        _area_sports = arcpy.conversion.FeatureClassToFeatureClass(in_features=pois_area_, out_path=_area_pois_gdb, out_name=f\"{area}_sports\", where_clause=\"(code >= 2251 And code <= 2257)\", field_mapping=\"code \\\"code\\\" true true false 4 Short 0 4,First,#,{pois_raw},code,-1,-1;fclass \\\"fclass\\\" true true false 28 Text 0 0,First,#,{pois_raw},fclass,0,28\")[0]\n",
    "        # Process: create catering (Feature Class To Feature Class) (conversion)\n",
    "        _area_catering = arcpy.conversion.FeatureClassToFeatureClass(in_features=pois_area_, out_path=_area_pois_gdb, out_name=f\"{area}_catering\", where_clause=\"code >= 2301 And code <= 2307 Or code = 2502\", field_mapping=\"code \\\"code\\\" true true false 4 Short 0 4,First,#,{pois_raw},code,-1,-1;fclass \\\"fclass\\\" true true false 28 Text 0 0,First,#,{pois_raw},fclass,0,28\")[0]\n",
    "        # Process: create shopping (Feature Class To Feature Class) (conversion)\n",
    "        _area_shopping = arcpy.conversion.FeatureClassToFeatureClass(in_features=pois_area_, out_path=_area_pois_gdb, out_name=f\"{area}_shopping\", where_clause=\"(code >= 2512 And code <= 2530) Or code >= 2542 And code <= 2561 Or code = 2568\", field_mapping=\"code \\\"code\\\" true true false 4 Short 0 4,First,#,{pois_raw},code,-1,-1;fclass \\\"fclass\\\" true true false 28 Text 0 0,First,#,{pois_raw},fclass,0,28\")[0]\n",
    "        # Process: create supermarket (Feature Class To Feature Class) (conversion)\n",
    "        _area_supermarket = arcpy.conversion.FeatureClassToFeatureClass(in_features=pois_area_, out_path=_area_pois_gdb, out_name=f\"{area}_supermarket\", where_clause=\"(code >= 2503 And code <= 2511) Or (code = 2501) Or code = 2016\", field_mapping=\"code \\\"code\\\" true true false 4 Short 0 4,First,#,{pois_raw},code,-1,-1;fclass \\\"fclass\\\" true true false 28 Text 0 0,First,#,{pois_raw},fclass,0,28\")[0]\n",
    "        # Process: create financial (Feature Class To Feature Class) (conversion)\n",
    "        _area_financial = arcpy.conversion.FeatureClassToFeatureClass(in_features=pois_area_, out_path=_area_pois_gdb, out_name=f\"{area}_financial\", where_clause=\"(code >= 2601 And code <= 2602)\", field_mapping=\"code \\\"code\\\" true true false 4 Short 0 4,First,#,{pois_raw},code,-1,-1;fclass \\\"fclass\\\" true true false 28 Text 0 0,First,#,{pois_raw},fclass,0,28\")[0]\n",
    "        # Process: create education (Feature Class To Feature Class) (conversion)\n",
    "        _area_education = arcpy.conversion.FeatureClassToFeatureClass(in_features=pois_area_, out_path=_area_pois_gdb, out_name=f\"{area}_education\", where_clause=\"code >= 2082 And code <= 2083\", field_mapping=\"code \\\"code\\\" true true false 4 Short 0 4,First,#,{pois_raw},code,-1,-1;fclass \\\"fclass\\\" true true false 28 Text 0 0,First,#,{pois_raw},fclass,0,28\")[0]\n",
    "        # Process: create facilities (Feature Class To Feature Class) (conversion)\n",
    "        _area_facilities = arcpy.conversion.FeatureClassToFeatureClass(in_features=pois_area_, out_path=_area_pois_gdb, out_name=f\"{area}_facilities\", where_clause=\"code = 2001 Or code = 2002 Or code = 2007 Or code = 2012 Or code = 2003\", field_mapping=\"code \\\"code\\\" true true false 4 Short 0 4,First,#,{pois_raw},code,-1,-1;fclass \\\"fclass\\\" true true false 28 Text 0 0,First,#,{pois_raw},fclass,0,28\")[0]\n",
    "        # Process: create worship (Feature Class To Feature Class) (conversion)\n",
    "        _area_worship = arcpy.conversion.FeatureClassToFeatureClass(in_features=pois_area_, out_path=_area_pois_gdb, out_name=f\"{area}_worship\", where_clause=\"(code >= 3100 And code <= 3800)\", field_mapping=\"osm_id \\\"osm_id\\\" true true false 12 Text 0 0,First,#,{pois_raw},osm_id,0,12;code \\\"code\\\" true true false 4 Short 0 4,First,#,{pois_raw},code,-1,-1;fclass \\\"fclass\\\" true true false 28 Text 0 0,First,#,{pois_raw},fclass,0,28\")[0]\n",
    "        # Process: create transport (Feature Class To Feature Class) (conversion)\n",
    "        _area_transport = arcpy.conversion.FeatureClassToFeatureClass(in_features=pois_area_, out_path=_area_pois_gdb, out_name=f\"{area}_transport\", where_clause=\"code >= 5601 And code <= 5641\", field_mapping=\"osm_id \\\"osm_id\\\" true true false 12 Text 0 0,First,#,{pois_raw},osm_id,0,12;code \\\"code\\\" true true false 4 Short 0 4,First,#,{pois_raw},code,-1,-1;fclass \\\"fclass\\\" true true false 28 Text 0 0,First,#,{pois_raw},fclass,0,28\")[0]\n",
    "        \n",
    "        # parks\n",
    "        # Process: create greenspace (Feature Class To Feature Class) (conversion)\n",
    "        greenspace = arcpy.conversion.FeatureClassToFeatureClass(in_features=landuse_raw.__str__().format(**globals()), out_path=_area_others_gdb, out_name=\"greenspace\", where_clause=\"code_2018 = '14100' Or code_2018 = '31000' Or code_2018 = '23000' Or code_2018 = '31000' Or code_2018 = '32000' Or code_2018 = '14200'\", field_mapping=\"code_2018 \\\"code_2018\\\" true true false 5 Text 0 0,First,#,{landuse_raw},code_2018,0,5\")[0]\n",
    "        # Process: Dissolve greenspace (Dissolve) (management)\n",
    "        greenspace_dissolve = fr\"{folder}\\{area}\\{area}_others.gdb\\greenspace_Dissolve\"\n",
    "        arcpy.management.Dissolve(in_features=greenspace, out_feature_class=greenspace_dissolve)\n",
    "        # Process: Intersect greenspace (Intersect) (analysis)\n",
    "        _area_greenspcae = fr\"{folder}\\{area}\\{area}_others.gdb\\greenspace_{area}\"\n",
    "        arcpy.analysis.Intersect(in_features=[[greenspace_dissolve, \"\"], [_area_Buffer, \"\"]], out_feature_class=_area_greenspcae, join_attributes=\"ONLY_FID\")\n",
    "        # Process: Polygon To Line (Polygon To Line) (management)\n",
    "        greenspace_line = fr\"{folder}\\{area}\\{area}_others.gdb\\greenspace_line\"\n",
    "        arcpy.management.PolygonToLine(in_features=_area_greenspcae, out_feature_class=greenspace_line)\n",
    "        # Process: Generate Points Along Lines (Generate Points Along Lines) (management)\n",
    "        greenspace_point = fr\"{folder}\\{area}\\{area}_others.gdb\\greenspace_point\"\n",
    "        arcpy.management.GeneratePointsAlongLines(Input_Features=greenspace_line, Output_Feature_Class=greenspace_point, Point_Placement=\"DISTANCE\", Distance=\"200 Meters\", Include_End_Points=\"NO_END_POINTS\")\n",
    "        # Process: create greenspcae_pointtojoin (Feature Class To Feature Class) (conversion)\n",
    "        greenspace_pointtojoin = arcpy.conversion.FeatureClassToFeatureClass(in_features=greenspace_point, out_path=_area_others_gdb, out_name=\"greenspace_pointtojoin\", field_mapping=\"Shape_length \\\"Shape_length\\\" true true false 0 Double 0 0,First,#,greenspace_point,Shape_Length,-1,-1;LEFT_FID \\\"LEFT_FID\\\" true true false 0 Long 0 0,First,#,greenspace_point,LEFT_FID,-1,-1;RIGHT_FID \\\"RIGHT_FID\\\" true true false 0 Long 0 0,First,#,greenspace_point,RIGHT_FID,-1,-1;ORIG_FID \\\"ORIG_FID\\\" true true false 0 Short 0 0,First,#,greenspace_point,ORIG_FID,-1,-1\")[0]\n",
    "        # Process: Add Fields (multiple) (Add Fields (multiple)) (management)\n",
    "        greenspace_pointtojoin2 = arcpy.management.AddFields(in_table=greenspace_pointtojoin, field_description=[[\"code\", \"SHORT\", \"\", \"\", \"2207\", \"\"], [\"fclass\", \"TEXT\", \"\", \"255\", \"greenspace\", \"\"]])[0]\n",
    "        # Process: create parks_pointtojoin (Feature Class To Feature Class) (conversion)\n",
    "        parks_pointtojoin = arcpy.conversion.FeatureClassToFeatureClass(in_features=pois_area_, out_path=_area_others_gdb, out_name=\"parks_pointtojoin\", where_clause=\"(code >= 2204 And code <= 2206)\", field_mapping=\"code \\\"code\\\" true true false 4 Short 0 4,First,#,{pois_raw},code,-1,-1;fclass \\\"fclass\\\" true true false 28 Text 0 0,First,#,{pois_raw},fclass,0,28\")[0]\n",
    "        # Process: Merge parks (Merge) (management)\n",
    "        arcpy.management.Merge(inputs=[greenspace_pointtojoin2, parks_pointtojoin], output=_area_parks.__str__().format(**globals()), field_mappings=\"code \\\"code\\\" true true false 0 Short 0 0,First,#,greenspace_pointtojoin2,code,-1,-1,parks_pointtojoin,code,-1,-1;fclass \\\"fclass\\\" true true false 255 Text 0 0,First,#,greenspace_pointtojoin2,fclass,0,255,parks_pointtojoin,fclass,0,28\")\n",
    "        # Directly use TableToTable conversion to overwrite the original table\n",
    "        arcpy.conversion.TableToTable(_area_parks.__str__().format(**globals()), _area_others_gdb, os.path.basename(_area_parks.__str__().format(**globals())))\n",
    "        \n",
    "        #population\n",
    "        # Process: Extract by Mask (Extract by Mask) (sa)\n",
    "        _area_population_raw = fr\"{folder}\\{area}\\{area}_others.gdb\\{area}_population_raw\"\n",
    "        Extract_by_Mask = _area_population_raw\n",
    "        _area_population_raw = arcpy.sa.ExtractByMask(population_raw.__str__().format(**globals()), _area_Buffer, \"INSIDE\", \"501584.2233 153855.1252 563984.662575463 202984.882819595 PROJCS[\\\"British_National_Grid\\\",GEOGCS[\\\"GCS_OSGB_1936\\\",DATUM[\\\"D_OSGB_1936\\\",SPHEROID[\\\"Airy_1830\\\",6377563.396,299.3249646]],PRIMEM[\\\"Greenwich\\\",0.0],UNIT[\\\"Degree\\\",0.0174532925199433]],PROJECTION[\\\"Transverse_Mercator\\\"],PARAMETER[\\\"False_Easting\\\",400000.0],PARAMETER[\\\"False_Northing\\\",-100000.0],PARAMETER[\\\"Central_Meridian\\\",-2.0],PARAMETER[\\\"Scale_Factor\\\",0.9996012717],PARAMETER[\\\"Latitude_Of_Origin\\\",49.0],UNIT[\\\"Meter\\\",1.0]]\")\n",
    "        _area_population_raw.save(Extract_by_Mask)\n",
    "        # Process: Raster to Point (Raster to Point) (conversion)\n",
    "        population_point = fr\"{folder}\\{area}\\{area}_others.gdb\\population_point\"\n",
    "        with arcpy.EnvManager(outputMFlag=\"Disabled\", outputZFlag=\"Disabled\"):\n",
    "            arcpy.conversion.RasterToPoint(in_raster=_area_population_raw, out_point_features=population_point)\n",
    "        # Process: Select more than 0 (Select) (analysis)\n",
    "        population_point_Select = fr\"{folder}\\{area}\\{area}_others.gdb\\population_point_Select\"\n",
    "        arcpy.analysis.Select(in_features=population_point, out_feature_class=population_point_Select, where_clause=\"grid_code > 0\")\n",
    "        # Process: Intersect (Intersect) (analysis)\n",
    "        arcpy.analysis.Intersect(in_features=[[_area_, \"\"], [population_point_Select, \"\"]], out_feature_class=_area_population.__str__().format(**globals()), join_attributes=\"ONLY_FID\")\n",
    "        # Define the desired output feature class\n",
    "        output_fc = _area_population.__str__().format(**globals())\n",
    "        arcpy.management.DeleteField(output_fc, [f.name for f in arcpy.ListFields(output_fc) if f.name not in ['OBJECTID', 'Shape', 'FID']])\n",
    "        \n",
    "        # roads\n",
    "        # Process: Intersect roads (Intersect) (analysis)\n",
    "        #arcpy.analysis.Intersect(in_features=[[_area_Buffer, \"\"], [roads_raw, \"\"]], out_feature_class=_area_roads.__str__().format(**globals()), join_attributes=\"NO_FID\")\n",
    "        \n",
    "        # return\n",
    "        # return analysis_area, _area_health, _area_leisure, _area_sports, _area_catering, _area_shopping, _area_supermarket, _area_financial, _area_education, _area_facilities, _area_worship, _area_transport, _area_parks, _area_roads, _area_population\n",
    "        def snap_and_remove_duplicates(input_fc, snap_environment, search_distance=\"100 Meters\"):\n",
    "            # Snap points to the given snap environment\n",
    "            arcpy.Snap_edit(input_fc, [[snap_environment, \"VERTEX\", search_distance]])\n",
    "            # Use Delete Identical to remove duplicates based on their SHAPE (location)\n",
    "            arcpy.DeleteIdentical_management(input_fc, [\"SHAPE\"])\n",
    "            \n",
    "        def process_geodatabase(gdb_path):\n",
    "            # Find the 'others' geodatabase in the same directory as the input geodatabase\n",
    "            directory = os.path.dirname(gdb_path)\n",
    "            other_gdb = [os.path.join(directory, gdb) for gdb in os.listdir(directory) if 'others' in gdb and gdb.endswith('.gdb')][0]\n",
    "            # Path to the 'population_point' feature class in the 'others' geodatabase\n",
    "            snap_environment = os.path.join(other_gdb, \"population_point\")\n",
    "            # Set the workspace to the input geodatabase\n",
    "            arcpy.env.workspace = gdb_path\n",
    "            # List all the feature classes in the geodatabase\n",
    "            fcs = arcpy.ListFeatureClasses(feature_type='Point')\n",
    "            # Process each point feature class\n",
    "            for fc in fcs:\n",
    "                snap_and_remove_duplicates(fc, snap_environment)\n",
    "        process_geodatabase(_area_pois_gdb)\n",
    "        \n",
    "    #analysis_area, _area_health, _area_leisure, _area_sports, _area_catering, _area_shopping, _area_supermarket, _area_financial, _area_education, _area_facilities, _area_worship, _area_transport, _area_parks, _area_roads, _area_population = dataselect(folder, area, area_type, area_raw, population_raw, pois_raw, roads_raw, landuse_raw)\n",
    "    dataselect(folder, area, area_type, area_raw, population_raw, pois_raw, roads_raw, landuse_raw)\n",
    "    #return analysis_area, _area_health, _area_leisure, _area_sports, _area_catering, _area_shopping, _area_supermarket, _area_financial, _area_education, _area_facilities, _area_worship, _area_transport, _area_parks, _area_roads, _area_population\n",
    "    \n",
    "    \n",
    "### run\n",
    "with arcpy.EnvManager(outputCoordinateSystem=\"PROJCS[\\\"British_National_Grid\\\",GEOGCS[\\\"GCS_OSGB_1936\\\",DATUM[\\\"D_OSGB_1936\\\",SPHEROID[\\\"Airy_1830\\\",6377563.396,299.3249646]],PRIMEM[\\\"Greenwich\\\",0.0],UNIT[\\\"Degree\\\",0.0174532925199433]],PROJECTION[\\\"Transverse_Mercator\\\"],PARAMETER[\\\"False_Easting\\\",400000.0],PARAMETER[\\\"False_Northing\\\",-100000.0],PARAMETER[\\\"Central_Meridian\\\",-2.0],PARAMETER[\\\"Scale_Factor\\\",0.9996012717],PARAMETER[\\\"Latitude_Of_Origin\\\",49.0],UNIT[\\\"Meter\\\",1.0]]\", scratchWorkspace=folder, workspace=folder):\n",
    "    datapreparation(folder, area, area_type)\n",
    "    arcpy.SetParameter(3, True)\n",
    "    arcpy.AddMessage(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### demandanalysis.py\n",
    "\n",
    "***Parameters***\n",
    "\n",
    "|Name|Data Type|Type|Direction|\n",
    "|---|---|---|---|\n",
    "|folder|Folder|Required|Input|\n",
    "|area|String|Required|Input|\n",
    "|success|Boolean|Derived|Output|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### input parameter\n",
    "folder=arcpy.GetParameterAsText(0)\n",
    "area=arcpy.GetParameterAsText(1)\n",
    "\n",
    "\n",
    "### import\n",
    "import arcpy\n",
    "from arcpy.sa import *\n",
    "from sys import argv\n",
    "import os\n",
    "\n",
    "\n",
    "### environment\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.workspace = folder\n",
    "\n",
    "        \n",
    "### define functions\n",
    "def demandcalculator(area, folder):\n",
    "    _area_ = fr\"{folder}\\{area}\"                \n",
    "    # Process: Create File Geodatabase analysis (Create File Geodatabase) (management)\n",
    "    _area_results_gdb = arcpy.management.CreateFileGDB(out_folder_path=_area_, out_name=f\"{area}_results\")[0]\n",
    "    \n",
    "    def FeatureClassGenerator(workspace, wild_card, feature_type, recursive) :\n",
    "        with arcpy.EnvManager(workspace = workspace):\n",
    "            dataset_list = [\"\"]\n",
    "            if recursive:\n",
    "                datasets = arcpy.ListDatasets()\n",
    "                dataset_list.extend(datasets)\n",
    "            for dataset in dataset_list:\n",
    "                featureclasses = arcpy.ListFeatureClasses(wild_card, feature_type, dataset)\n",
    "                for fc in featureclasses:\n",
    "                    yield os.path.join(workspace, dataset, fc), fc\n",
    "                    \n",
    "    def get_latest_feature_dataset_in_gdb(gdb_path):\n",
    "            arcpy.env.workspace = gdb_path\n",
    "            feature_datasets = arcpy.ListDatasets()\n",
    "            if not feature_datasets:\n",
    "                return None\n",
    "            return feature_datasets[-1]\n",
    "     \n",
    "    def demandanalysis(walkdistance, area, folder, category):\n",
    "        arcpy.ImportToolbox(r\"C:\\Users\\xianl\\Documents\\ArcGIS\\Projects\\CASA0010\\CASA0010.atbx\")\n",
    "        population = fr\"{folder}\\{area}\\{area}_population.gdb\\{area}_population\"\n",
    "        _area_pois_gdb = fr\"{folder}\\{area}\\{area}_pois.gdb\"\n",
    "        Network_Data_Source = \"https://www.arcgis.com/\"\n",
    "        IncidentID = \"IncidentID\"\n",
    "        \n",
    "        # Process: Create File Geodatabase analysis (Create File Geodatabase) (management)\n",
    "        _area_analysis_gdb = arcpy.management.CreateFileGDB(out_folder_path=_area_, out_name=f\"{area}_analysis\")[0]\n",
    "        _area_routes_gdb = arcpy.management.CreateFileGDB(out_folder_path=_area_, out_name=f\"{area}_routes\")[0]\n",
    "        _area_others_gdb = arcpy.management.CreateFileGDB(out_folder_path=_area_, out_name=f\"{area}_others\")[0]\n",
    "        _area_working_gdb = arcpy.management.CreateFileGDB(out_folder_path=_area_, out_name=f\"{area}_working\")[0]\n",
    "        \n",
    "        # Process: Project population (Project) (management)\n",
    "        _area_population_Project = fr\"{folder}\\{area}\\{area}_others.gdb\\{area}_population_Project\"\n",
    "        arcpy.management.Project(in_dataset=population, out_dataset=_area_population_Project, out_coor_system=\"GEOGCS[\\\"GCS_WGS_1984\\\",DATUM[\\\"D_WGS_1984\\\",SPHEROID[\\\"WGS_1984\\\",6378137.0,298.257223563]],PRIMEM[\\\"Greenwich\\\",0.0],UNIT[\\\"Degree\\\",0.0174532925199433]]\", in_coor_system=\"PROJCS[\\\"British_National_Grid\\\",GEOGCS[\\\"GCS_OSGB_1936\\\",DATUM[\\\"D_OSGB_1936\\\",SPHEROID[\\\"Airy_1830\\\",6377563.396,299.3249646]],PRIMEM[\\\"Greenwich\\\",0.0],UNIT[\\\"Degree\\\",0.0174532925199433]],PROJECTION[\\\"Transverse_Mercator\\\"],PARAMETER[\\\"False_Easting\\\",400000.0],PARAMETER[\\\"False_Northing\\\",-100000.0],PARAMETER[\\\"Central_Meridian\\\",-2.0],PARAMETER[\\\"Scale_Factor\\\",0.9996012717],PARAMETER[\\\"Latitude_Of_Origin\\\",49.0],UNIT[\\\"Meter\\\",1.0]]\")\n",
    "        # Process: Buffer population (Buffer) (analysis)\n",
    "        population_Buffer = fr\"{folder}\\{area}\\{area}_others.gdb\\{area}_population_Buffer\"\n",
    "        arcpy.analysis.Buffer(in_features=_area_population_Project, out_feature_class=population_Buffer, buffer_distance_or_field=f\"{walkdistance} Kilometers\", dissolve_option=\"ALL\")\n",
    "        \n",
    "        for FeatureClass, pois in FeatureClassGenerator(_area_pois_gdb, \"\", \"POINT\", \"NOT_RECURSIVE\"):\n",
    "            # Process: Table To Table (Table To Table) (conversion)\n",
    "            _pois_demand = arcpy.conversion.TableToTable(in_rows=population, out_path=_area_others_gdb, out_name=f\"{pois}_demand\", field_mapping=\"ID \\\"ID\\\" true true false 255 Long 0 0,First,#,\" + population + \",OBJECTID,-1,-1\")\n",
    "            arcpy.env.workspace = fr\"{folder}\\{area}\\{area}_working.gdb\"\n",
    "            # Process: Make Closest Facility Analysis Layer (Make Closest Facility Analysis Layer) (na)\n",
    "            Closest_Facility_n_ = arcpy.na.MakeClosestFacilityAnalysisLayer(network_data_source=Network_Data_Source, layer_name=f\"{pois}_{category}_closestfacility\", travel_mode=\"Walking Distance\", travel_direction=\"TO_FACILITIES\", cutoff=walkdistance.__str__().format(**globals()), time_of_day=\"2023/9/1\", line_shape=\"NO_LINES\", ignore_invalid_locations=\"HALT\")[0]\n",
    "            # Process: Add population (Add Locations) (na)\n",
    "            with_population = arcpy.na.AddLocations(in_network_analysis_layer=Closest_Facility_n_, sub_layer=\"Incidents\", in_table=_area_population_Project, sort_field=\"OBJECTID\", append=\"CLEAR\")[0]\n",
    "            # Process: Project facilities (Project) (management)\n",
    "            _pois_Project = fr\"{folder}\\{area}\\{area}_others.gdb\\{pois}_Project\"\n",
    "            arcpy.management.Project(in_dataset=FeatureClass, out_dataset=_pois_Project, out_coor_system=\"GEOGCS[\\\"GCS_WGS_1984\\\",DATUM[\\\"D_WGS_1984\\\",SPHEROID[\\\"WGS_1984\\\",6378137.0,298.257223563]],PRIMEM[\\\"Greenwich\\\",0.0],UNIT[\\\"Degree\\\",0.0174532925199433]]\")\n",
    "            # Process: Intersect (Intersect) (analysis)\n",
    "            facilities_inwalkdistance = fr\"{folder}\\{area}\\{area}_others.gdb\\{pois}_inwalkdistance\"\n",
    "            arcpy.analysis.Intersect(in_features=[[population_Buffer, \"\"], [_pois_Project, \"\"]], out_feature_class=facilities_inwalkdistance)\n",
    "            # Process: Add facilities (Add Locations) (na)\n",
    "            with_facilities = arcpy.na.AddLocations(in_network_analysis_layer=with_population, sub_layer=\"Facilities\", in_table=facilities_inwalkdistance, sort_field=\"OBJECTID\", append=\"CLEAR\")[0]\n",
    "            # Check if facilities_inwalkdistance is empty\n",
    "            count = int(arcpy.GetCount_management(facilities_inwalkdistance).getOutput(0))\n",
    "            if count == 0:\n",
    "                # Create an empty feature class with specified fields\n",
    "                arcpy.CreateFeatureclass_management(out_path=fr\"{folder}\\{area}\\{area}_routes.gdb\", out_name=f\"{pois}_routes\", geometry_type=\"POLYLINE\")\n",
    "                arcpy.AddField_management(in_table=fr\"{folder}\\{area}\\{area}_routes.gdb\\{pois}_routes\", field_name=\"IncidentID\", field_type=\"LONG\")\n",
    "                arcpy.AddField_management(in_table=fr\"{folder}\\{area}\\{area}_routes.gdb\\{pois}_routes\", field_name=\"Total_WalkTime\", field_type=\"DOUBLE\")\n",
    "            else:\n",
    "                # Process: Solve (Solve) (na)\n",
    "                Closest_Facility_result = arcpy.na.Solve(in_network_analysis_layer=with_facilities, ignore_invalids=\"SKIP\", terminate_on_solve_error=\"TERMINATE\", overrides=Network_Data_Source)\n",
    "                def find_and_export_route_features(gdb_path, feature_dataset_name, output_folder):\n",
    "                    arcpy.env.workspace = os.path.join(gdb_path, feature_dataset_name)\n",
    "                    feature_classes = arcpy.ListFeatureClasses()\n",
    "                    route_features = [fc for fc in feature_classes if 'Route' in fc]\n",
    "                    for route_feature in route_features:\n",
    "                        new_name = fr\"{pois}_routes\"\n",
    "                        output_path = os.path.join(output_folder, new_name)\n",
    "                        arcpy.CopyFeatures_management(route_feature, output_path) \n",
    "                latest_dataset = get_latest_feature_dataset_in_gdb(fr\"{folder}\\{area}\\{area}_working.gdb\")\n",
    "                find_and_export_route_features(fr\"{folder}\\{area}\\{area}_working.gdb\", latest_dataset, fr\"{folder}\\{area}\\{area}_routes.gdb\")\n",
    "                arcpy.Delete_management(os.path.join(fr\"{folder}\\{area}\\{area}_working.gdb\", latest_dataset))\n",
    "            Routes = fr\"{folder}\\{area}\\{area}_routes.gdb\\{pois}_routes\"\n",
    "            # Process: export routes (Table To Table) (conversion)\n",
    "            _pois_routes = arcpy.conversion.TableToTable(\n",
    "                in_rows=Routes,\n",
    "                out_path=_area_others_gdb,\n",
    "                out_name=f\"{pois}_routes\",\n",
    "                field_mapping=\"IncidentID \\\"IncidentID\\\" true true true 4 Long 0 0,First,#,ModelBuilder\\\\Routes:Routes,IncidentID,-1,-1;Total_WalkTime \\\"Total_WalkTime\\\" true true true 8 Double 0 0,First,#,ModelBuilder\\\\Routes:Routes,Total_WalkTime,-1,-1\"\n",
    "            )[0]\n",
    "            # Process: Join Field (Join Field) (management)\n",
    "            _pois_demand_2_ = arcpy.management.JoinField(\n",
    "                in_data=_pois_demand,\n",
    "                in_field=\"ID\",\n",
    "                join_table=_pois_routes,\n",
    "                join_field=\"IncidentID\",\n",
    "                fields=[\"Total_WalkTime\"]\n",
    "            )[0]\n",
    "            _pois_category_demandresult = arcpy.conversion.TableToTable(\n",
    "                in_rows=_pois_demand_2_,\n",
    "                out_path=_area_analysis_gdb,\n",
    "                out_name=f\"{pois}_{category}_demandresult\",\n",
    "            )[0]\n",
    "            arcpy.AddField_management(in_table=_pois_category_demandresult, field_name=f\"{pois}_demand\", field_type=\"FLOAT\")\n",
    "            result_calculate = arcpy.management.CalculateField(\n",
    "                in_table=_pois_category_demandresult,\n",
    "                field=f\"{pois}_demand\",\n",
    "                expression=\"0.0 if !Total_WalkTime! == None else math.exp(-0.073 * !Total_WalkTime!)\",\n",
    "                expression_type=\"PYTHON3\",\n",
    "                code_block=\"import math\"\n",
    "            )[0]\n",
    "            # Process: Delete Field (Delete Field) (management)\n",
    "            Update_result = arcpy.management.DeleteField(in_table=result_calculate, drop_field=[IncidentID])[0]\n",
    "       \n",
    "        # define demandcalculate\n",
    "        def demandcalculate(output_table_path):\n",
    "            input_gdb = fr\"{folder}\\{area}\\{area}_analysis.gdb\"\n",
    "            arcpy.env.workspace = input_gdb\n",
    "            tables = arcpy.ListTables()\n",
    "            arcpy.Copy_management(tables[0], output_table_path)\n",
    "            arcpy.DeleteField_management(output_table_path, [\"ID\", \"Total_WalkTime\"])\n",
    "\n",
    "            for table in tables[1:]:\n",
    "                fields = arcpy.ListFields(table)\n",
    "                second_column = fields[3].name\n",
    "                arcpy.JoinField_management(output_table_path, \"OBJECTID\", table, \"OBJECTID\", [second_column])\n",
    "            fields = arcpy.ListFields(output_table_path)\n",
    "            sum_fields = [f.name for f in fields if f.name != 'OBJECTID']\n",
    "            \n",
    "            # Add new field for demandresult and calculate its value\n",
    "            arcpy.AddField_management(output_table_path, \"demandresult\", \"FLOAT\")\n",
    "            with arcpy.da.UpdateCursor(output_table_path, sum_fields + [\"demandresult\"]) as cursor:\n",
    "                for row in cursor:\n",
    "                    total = sum(row[:-1])\n",
    "                    average = total / 12.0\n",
    "                    row[-1] = average\n",
    "                    cursor.updateRow(row)\n",
    "            \n",
    "        # Process: demandcalculate (demandcalculate)     \n",
    "        demandcalculate(output_table_path=fr\"{folder}\\{area}\\{area}_results.gdb\\{area}_{category}_demandresult\")\n",
    "        arcpy.JoinField_management(fr\"{folder}\\{area}\\{area}_population.gdb\\{area}_population\", \"OBJECTID\", fr\"{folder}\\{area}\\{area}_results.gdb\\{area}_{category}_demandresult\", \"OBJECTID\")\n",
    "\n",
    "    with arcpy.da.SearchCursor(f\"{folder}\\\\input\\\\walkdistance.csv\", ['category', 'distance15']) as cursor:\n",
    "        for row in cursor:\n",
    "            category = row[0]\n",
    "            walkdistance = row[1]\n",
    "            if category == 'standard':  # only calculate standard category\n",
    "                demandanalysis(walkdistance, area, folder, category)\n",
    "                break  # only calculate standard category\n",
    "\n",
    "\n",
    "### run\n",
    "with arcpy.EnvManager(outputCoordinateSystem=\"PROJCS[\\\"British_National_Grid\\\",GEOGCS[\\\"GCS_OSGB_1936\\\",DATUM[\\\"D_OSGB_1936\\\",SPHEROID[\\\"Airy_1830\\\",6377563.396,299.3249646]],PRIMEM[\\\"Greenwich\\\",0.0],UNIT[\\\"Degree\\\",0.0174532925199433]],PROJECTION[\\\"Transverse_Mercator\\\"],PARAMETER[\\\"False_Easting\\\",400000.0],PARAMETER[\\\"False_Northing\\\",-100000.0],PARAMETER[\\\"Central_Meridian\\\",-2.0],PARAMETER[\\\"Scale_Factor\\\",0.9996012717],PARAMETER[\\\"Latitude_Of_Origin\\\",49.0],UNIT[\\\"Meter\\\",1.0]]\", scratchWorkspace=folder, workspace=folder):\n",
    "    demandcalculator(area, folder)\n",
    "    arcpy.SetParameter(2, True)\n",
    "    arcpy.AddMessage(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### supplyanalysis.py\n",
    "\n",
    "***Parameters***\n",
    "\n",
    "|Name|Data Type|Type|Direction|\n",
    "|---|---|---|---|\n",
    "|folder|Folder|Required|Input|\n",
    "|area|String|Required|Input|\n",
    "|area_type|String|Required|Input|\n",
    "|success|Boolean|Derived|Output|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import\n",
    "import arcpy\n",
    "import os\n",
    "from sys import argv\n",
    "\n",
    "\n",
    "### input parameter\n",
    "folder=arcpy.GetParameterAsText(0)\n",
    "area=arcpy.GetParameterAsText(1)\n",
    "area_type=arcpy.GetParameterAsText(2)\n",
    "\n",
    "\n",
    "### environment\n",
    "arcpy.env.workspace = folder\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "\n",
    "### define functions\n",
    "def split_by_count(input_fc, count=999):\n",
    "    # Get a list of OBJECTIDs from the input feature class\n",
    "    objectids = [row[0] for row in arcpy.da.SearchCursor(input_fc, 'OBJECTID')]\n",
    "    total_count = len(objectids)\n",
    "    # If the total count is less than or equal to the specified count, exit the function\n",
    "    if total_count <= count:\n",
    "        return\n",
    "    # Create a feature layer from the input feature class\n",
    "    arcpy.management.MakeFeatureLayer(input_fc, \"temp_layer\")\n",
    "    # Retrieve the directory and the name of the input feature class\n",
    "    folder_path, fc_name = os.path.split(input_fc)\n",
    "    fc_name_noext = os.path.splitext(fc_name)[0]  # Get the name without the extension\n",
    "    start_index = 0\n",
    "    chunk_num = 1\n",
    "    while start_index < total_count:\n",
    "        end_index = start_index + count\n",
    "        if end_index > total_count:\n",
    "            end_index = total_count\n",
    "        current_ids = objectids[start_index:end_index]\n",
    "        sql_query = \"OBJECTID IN ({})\".format(','.join(map(str, current_ids)))\n",
    "        # Select the subset of features\n",
    "        arcpy.management.SelectLayerByAttribute(\"temp_layer\", \"NEW_SELECTION\", sql_query)\n",
    "        # Name for the output feature class\n",
    "        output_fc = os.path.join(folder_path, f\"{fc_name_noext}_{chunk_num}\")\n",
    "        # Export the selected features to a new feature class\n",
    "        arcpy.management.CopyFeatures(\"temp_layer\", output_fc)\n",
    "        start_index = end_index\n",
    "        chunk_num += 1\n",
    "    # Remove the original feature class and the temporary feature layer\n",
    "    arcpy.management.Delete(input_fc)\n",
    "    arcpy.management.Delete(\"temp_layer\")\n",
    "\n",
    "def process_geodatabase(gdb_path):\n",
    "    # Set the workspace environment\n",
    "    arcpy.env.workspace = gdb_path\n",
    "    # List all the feature classes in the geodatabase\n",
    "    fcs = arcpy.ListFeatureClasses()\n",
    "    # Process each feature class\n",
    "    for fc in fcs:\n",
    "        split_by_count(fc)\n",
    "\n",
    "def FeatureClassGenerator(workspace, wild_card, feature_type, recursive) :\n",
    "    with arcpy.EnvManager(workspace = workspace):\n",
    "        dataset_list = [\"\"]\n",
    "        if recursive:\n",
    "            datasets = arcpy.ListDatasets()\n",
    "            dataset_list.extend(datasets)\n",
    "            for dataset in dataset_list:\n",
    "                featureclasses = arcpy.ListFeatureClasses(wild_card, feature_type, dataset)\n",
    "                for fc in featureclasses:\n",
    "                    yield os.path.join(workspace, dataset, fc), fc\n",
    "\n",
    "def get_latest_feature_dataset_in_gdb(gdb_path):\n",
    "    arcpy.env.workspace = gdb_path\n",
    "    feature_datasets = arcpy.ListDatasets()\n",
    "    if not feature_datasets:\n",
    "        return None\n",
    "    return feature_datasets[-1]\n",
    "                    \n",
    "def supplyanalysis(_area_, _folder_):\n",
    "    # To allow overwriting outputs change overwriteOutput option to True.\n",
    "    arcpy.env.overwriteOutput = True\n",
    "    Network_Data_Source = \"https://www.arcgis.com/\"\n",
    "    _area_pois_gdb = fr\"{folder}\\{area}\\{area}_pois.gdb\"\n",
    "    _area_ = fr\"{folder}\\{area}\"\n",
    "    _area_sa_gdb = arcpy.management.CreateFileGDB(out_folder_path=_area_, out_name=f\"{area}_sa\")[0]\n",
    "    _area_working_gdb = arcpy.management.CreateFileGDB(out_folder_path=_area_, out_name=f\"{area}_working\")[0]\n",
    "    _area_others_gdb = arcpy.management.CreateFileGDB(out_folder_path=_area_, out_name=f\"{area}_others\")[0]\n",
    "    for pois_point, pois in FeatureClassGenerator(_area_pois_gdb, \"\", \"\", \"NOT_RECURSIVE\"):\n",
    "        # Process: Make Service Area Analysis Layer (Make Service Area Analysis Layer) (na)\n",
    "        arcpy.env.workspace = fr\"{folder}\\{area}\\{area}_working.gdb\"\n",
    "        Service_Area_layer = arcpy.na.MakeServiceAreaAnalysisLayer(network_data_source=Network_Data_Source, travel_mode=\"Walking Time\", cutoffs=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], time_of_day=\"2023/9/1\", polygon_detail=\"STANDARD\", geometry_at_overlaps=\"OVERLAP\", polygon_trim_distance=\"50 Meters\")[0]     \n",
    "        # Process: Add Facilities (Add Locations) (na)\n",
    "        Service_Area_layer_with_pois = arcpy.na.AddLocations(in_network_analysis_layer=Service_Area_layer, sub_layer=\"Facilities\", in_table=pois_point)[0]\n",
    "        # Check if pois_point is empty\n",
    "        feature_count = int(arcpy.GetCount_management(pois_point).getOutput(0))\n",
    "        if feature_count == 0:\n",
    "            # Create an empty polygon feature class named sa_{pois} with two float fields\n",
    "            output_fc_path = fr\"{folder}\\{area}\\{area}_sa.gdb\\sa_{pois}\"\n",
    "            arcpy.CreateFeatureclass_management(\n",
    "                out_path=fr\"{folder}\\{area}\\{area}_sa.gdb\",\n",
    "                out_name=f\"sa_{pois}\",\n",
    "                geometry_type=\"POLYGON\"\n",
    "            )\n",
    "            arcpy.AddField_management(output_fc_path, \"FromBreak\", \"FLOAT\")\n",
    "            arcpy.AddField_management(output_fc_path, \"ToBreak\", \"FLOAT\")\n",
    "        else:\n",
    "            # Process: Solve (Solve) (na)\n",
    "            Service_Area_result, Solve_Succeeded = arcpy.na.Solve(in_network_analysis_layer=Service_Area_layer_with_pois)\n",
    "            # Process: Select_Data (Select Data)      \n",
    "            def find_and_export_sa_features(gdb_path, feature_dataset_name, output_folder):\n",
    "                arcpy.env.workspace = os.path.join(gdb_path, feature_dataset_name)\n",
    "                feature_classes = arcpy.ListFeatureClasses()\n",
    "                sa_features = [fc for fc in feature_classes if 'SAPolygons' in fc]\n",
    "                for sa_feature in sa_features:\n",
    "                    new_name = fr\"sa_{pois}\"\n",
    "                    output_path = os.path.join(output_folder, new_name)\n",
    "                    arcpy.CopyFeatures_management(sa_feature, output_path)\n",
    "            latest_dataset = get_latest_feature_dataset_in_gdb(fr\"{folder}\\{area}\\{area}_working.gdb\")\n",
    "            find_and_export_sa_features(fr\"{folder}\\{area}\\{area}_working.gdb\", latest_dataset, fr\"{folder}\\{area}\\{area}_sa.gdb\")\n",
    "            arcpy.Delete_management(os.path.join(fr\"{folder}\\{area}\\{area}_working.gdb\", latest_dataset))\n",
    "\n",
    "# auto merge\n",
    "def get_common_name(fcs):\n",
    "    if len(fcs) >= 2:\n",
    "        return os.path.commonprefix(fcs).rstrip('_')\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def group_feature_classes_by_field(gdb):\n",
    "    arcpy.env.workspace = gdb\n",
    "    grouped_fcs = {}\n",
    "    # List all feature classes in the geodatabase\n",
    "    fcs = arcpy.ListFeatureClasses()\n",
    "    # Iterate over feature classes and group by the field between underscores\n",
    "    for fc in fcs:\n",
    "        parts = fc.split('_')\n",
    "        if len(parts) > 2:\n",
    "            key_field = parts[2]\n",
    "            if key_field not in grouped_fcs:\n",
    "                grouped_fcs[key_field] = []\n",
    "            grouped_fcs[key_field].append(fc)\n",
    "    return grouped_fcs\n",
    "\n",
    "def merge_and_rename_feature_classes_by_group(gdb):\n",
    "    grouped_fcs = group_feature_classes_by_field(gdb)\n",
    "    for key, fcs in grouped_fcs.items():\n",
    "        common_name = get_common_name(fcs)\n",
    "        if common_name:\n",
    "            # Merge the feature classes\n",
    "            temp_output_fc = f\"{common_name}_merged\"\n",
    "            arcpy.Merge_management(fcs, temp_output_fc)\n",
    "            # Rename the merged feature class by removing everything after the last underscore\n",
    "            final_name = \"_\".join(temp_output_fc.split('_')[:-1])\n",
    "            arcpy.Rename_management(temp_output_fc, final_name)\n",
    "            # Delete the source feature classes\n",
    "            for fc in fcs:\n",
    "                arcpy.Delete_management(fc)\n",
    "\n",
    "def supplycalculation(folder, area, area_type):\n",
    "    def FeatureClassGenerator(workspace, wild_card, feature_type, recursive) :\n",
    "            with arcpy.EnvManager(workspace = workspace):\n",
    "                dataset_list = [\"\"]\n",
    "                if recursive:\n",
    "                    datasets = arcpy.ListDatasets()\n",
    "                    dataset_list.extend(datasets)\n",
    "                for dataset in dataset_list:\n",
    "                    featureclasses = arcpy.ListFeatureClasses(wild_card, feature_type, dataset)\n",
    "                    for fc in featureclasses:\n",
    "                        yield os.path.join(workspace, dataset, fc), fc\n",
    "    # Process: Dissolve (Dissolve) (management)\n",
    "    _area_area_type_dissolve = fr\"{folder}\\{area}\\{area}_others.gdb\\{area}_{area_type}_dissolve\"\n",
    "    arcpy.management.Dissolve(in_features=fr\"{folder}\\{area}\\{area}_boundaries.gdb\\{area}_{area_type}\", out_feature_class=_area_area_type_dissolve)\n",
    "            \n",
    "    # supplycalculate\n",
    "    def supplycalculate(folder, area, area_type):\n",
    "        # To allow overwriting outputs change overwriteOutput option to True.\n",
    "        arcpy.env.overwriteOutput = True\n",
    "        _area_population = fr\"{folder}\\{area}\\{area}_population.gdb\\{area}_population\"\n",
    "        _area_sa_gdb = fr\"{folder}\\{area}\\{area}_sa.gdb\"\n",
    "        _area_area_type_dissolve = fr\"{folder}\\{area}\\{area}_others.gdb\\{area}_{area_type}_dissolve\"\n",
    "        for pois_supply, pois in FeatureClassGenerator(_area_sa_gdb, \"\", \"\", \"NOT_RECURSIVE\"):\n",
    "            # Process: Calculate time (Calculate Field) (management)\n",
    "            pois_supply_1_ = arcpy.management.CalculateField(in_table=pois_supply, field=\"time\", expression=\"($feature.FromBreak + $feature.ToBreak) / 2\", expression_type=\"ARCADE\", field_type=\"DOUBLE\")[0]\n",
    "            # Process: Calculate supply (Calculate Field) (management)\n",
    "            pois_supply_2_ = arcpy.management.CalculateField(in_table=pois_supply_1_, field=f\"{pois}_supply\", expression=\"0 if !time! is None else float(math.exp(-0.073 * !time!))\", code_block=\"import math\", field_type=\"DOUBLE\")[0]\n",
    "            # Process: Spatial Join (Spatial Join) (analysis)\n",
    "            _area_population_2_ = fr\"{folder}\\{area}\\{area}_analysis.gdb\\{pois}_population\"\n",
    "            field_mapping = (\n",
    "                f\"\\\"{pois}_supply\\\" \"\n",
    "                f\"\\\"{pois}_supply\\\" \"\n",
    "                \"true true false \"\n",
    "                \"4 Float 0 0 ,\"\n",
    "                \"Sum,\"\n",
    "                \"#,\"\n",
    "                fr\"\\\"{folder}\\\\{area}\\\\{area}_sa.gdb\\\\sa_{pois}\\\",\"\n",
    "                f\"\\\"{pois[:2].upper()}{pois[2:]}_supply\\\",\"\n",
    "                \"-1,-1\"\n",
    "            )\n",
    "            arcpy.analysis.SpatialJoin(target_features=_area_population, join_features=pois_supply_2_, out_feature_class=_area_population_2_, join_operation=\"JOIN_ONE_TO_ONE\", field_mapping=field_mapping)\n",
    "    supplycalculate(folder, area, area_type)    \n",
    "    \n",
    "    def process_fields_and_data(folder, area):\n",
    "        area_analysis_gdb = fr\"{folder}\\{area}\\{area}_analysis.gdb\"\n",
    "        population_gdb = fr\"{folder}\\{area}\\{area}_population.gdb\\{area}_population\"\n",
    "        \n",
    "        for pois_pop, _ in FeatureClassGenerator(area_analysis_gdb, \"*_population\", \"\", \"NOT_RECURSIVE\"):\n",
    "            supply_fields = [f.name for f in arcpy.ListFields(pois_pop) if 'sa' in f.name.lower()]\n",
    "            for field in supply_fields:\n",
    "                old_field_name = field\n",
    "                new_field_name = field.split(\"_\", 1)[-1]\n",
    "                arcpy.JoinField_management(in_data=population_gdb, in_field=\"OBJECTID\", join_table=pois_pop, join_field=\"OBJECTID\", fields=[field])            \n",
    "                arcpy.AlterField_management(population_gdb, old_field_name, new_field_name, new_field_name)\n",
    "                with arcpy.da.UpdateCursor(population_gdb, new_field_name) as cursor:\n",
    "                    for row in cursor:\n",
    "                        if row[0] is None:\n",
    "                            row[0] = 0\n",
    "                        cursor.updateRow(row)\n",
    "    \n",
    "        supply_fields = [f.name for f in arcpy.ListFields(population_gdb) if 'supply' in f.name.lower()]\n",
    "        if \"supplyresult\" not in [f.name for f in arcpy.ListFields(population_gdb)]:\n",
    "            arcpy.AddField_management(population_gdb, \"supplyresult\", \"DOUBLE\")\n",
    "        \n",
    "        calculate_expression = \"({})/{}\".format(\" + \".join([\"!\" + f + \"!\" for f in supply_fields]), len(supply_fields))\n",
    "        arcpy.CalculateField_management(population_gdb, \"supplyresult\", calculate_expression, \"PYTHON3\")\n",
    "        \n",
    "        all_fields = [f.name for f in arcpy.ListFields(population_gdb)]\n",
    "    \n",
    "        for field in all_fields:\n",
    "            if \"_\" in field:\n",
    "                new_field_name = field.split(\"_\", 1)[-1]\n",
    "                arcpy.AlterField_management(population_gdb, field, new_field_name, new_field_name)\n",
    "    \n",
    "        output_gdb = fr\"{folder}\\{area}\\{area}_finalresult.gdb\"\n",
    "        if not arcpy.Exists(output_gdb):\n",
    "            arcpy.CreateFileGDB_management(fr\"{folder}\\{area}\", f\"{area}_finalresult.gdb\")\n",
    "        \n",
    "        arcpy.FeatureClassToFeatureClass_conversion(population_gdb, output_gdb, f\"{area}_result\")\n",
    "    process_fields_and_data(folder, area)\n",
    "      \n",
    "\n",
    "### run\n",
    "with arcpy.EnvManager(outputCoordinateSystem=\"PROJCS[\\\"British_National_Grid\\\",GEOGCS[\\\"GCS_OSGB_1936\\\",DATUM[\\\"D_OSGB_1936\\\",SPHEROID[\\\"Airy_1830\\\",6377563.396,299.3249646]],PRIMEM[\\\"Greenwich\\\",0.0],UNIT[\\\"Degree\\\",0.0174532925199433]],PROJECTION[\\\"Transverse_Mercator\\\"],PARAMETER[\\\"False_Easting\\\",400000.0],PARAMETER[\\\"False_Northing\\\",-100000.0],PARAMETER[\\\"Central_Meridian\\\",-2.0],PARAMETER[\\\"Scale_Factor\\\",0.9996012717],PARAMETER[\\\"Latitude_Of_Origin\\\",49.0],UNIT[\\\"Meter\\\",1.0]]\", scratchWorkspace=folder, workspace=folder):\n",
    "    gdb_input = fr\"{folder}\\{area}\\{area}_pois.gdb\"\n",
    "    process_geodatabase(gdb_input)\n",
    "    supplyanalysis(area, folder)\n",
    "    merge_and_rename_feature_classes_by_group(fr\"{folder}\\{area}\\{area}_sa.gdb\")\n",
    "    supplycalculation(folder, area, area_type)\n",
    "    arcpy.SetParameter(3, True)\n",
    "    arcpy.AddMessage(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resultcalculation.py\n",
    "\n",
    "***Parameters***\n",
    "\n",
    "|Name|Data Type|Type|Direction|\n",
    "|---|---|---|---|\n",
    "|folder|Folder|Required|Input|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import\n",
    "import arcpy\n",
    "from arcpy.sa import *\n",
    "from sys import argv\n",
    "import arcpy\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "import os\n",
    "\n",
    "\n",
    "### input parameter\n",
    "folder = arcpy.GetParameterAsText(0)\n",
    "\n",
    "\n",
    "### environment\n",
    "arcpy.env.workspace = folder\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "\n",
    "### functions\n",
    "  \n",
    "# merge result\n",
    "def merge_featureclasses_from_gdbs(folder):\n",
    "    all_featureclasses = []\n",
    "    for area in os.listdir(folder):\n",
    "        gdb_path = fr\"{folder}\\{area}\\{area}_finalresult.gdb\"\n",
    "        if os.path.exists(gdb_path):\n",
    "            arcpy.env.workspace = gdb_path\n",
    "            featureclasses = arcpy.ListFeatureClasses()\n",
    "            for fc in featureclasses:\n",
    "                all_featureclasses.append(os.path.join(gdb_path, fc))\n",
    "    if all_featureclasses:\n",
    "        arcpy.CreateFileGDB_management(folder, \"output.gdb\")\n",
    "        output_gdb = os.path.join(folder, \"output.gdb\")\n",
    "        output_fc_path = os.path.join(output_gdb, \"convenience\")\n",
    "        arcpy.Merge_management(all_featureclasses, output_fc_path)\n",
    "\n",
    "# delete gdbs\n",
    "def delete_specific_gdbs(folder):\n",
    "    for area in os.listdir(folder):\n",
    "        area_folder = os.path.join(folder, area)\n",
    "        if os.path.isdir(area_folder):\n",
    "            for gdb_name in os.listdir(area_folder):\n",
    "                if any(keyword in gdb_name.lower() for keyword in ['others', 'analysis', 'working', 'results']):\n",
    "                    gdb_path = os.path.join(area_folder, gdb_name)\n",
    "                    if arcpy.Exists(gdb_path) and arcpy.Describe(gdb_path).workspaceType == \"FileGDB\":\n",
    "                        arcpy.Delete_management(gdb_path)\n",
    "\n",
    "merge_featureclasses_from_gdbs(folder)\n",
    "delete_specific_gdbs(folder)\n",
    "\n",
    "fc = fr\"{folder}\\output.gdb\\convenience\"\n",
    "all_fields = [f.name for f in arcpy.ListFields(fc)]\n",
    "demand_fields = [f for f in all_fields if 'demand' in f.lower()]\n",
    "supply_fields = [f for f in all_fields if '_supply' in f.lower()]\n",
    "supplyresult_fields = [f for f in all_fields if 'supplyresult' in f.lower()]\n",
    "\n",
    "# Gather values from all the _supply fields\n",
    "all_supply_values = []\n",
    "\n",
    "for supply_field in supply_fields:\n",
    "    values = [row[0] for row in arcpy.da.SearchCursor(fc, supply_field)]\n",
    "    all_supply_values.extend(values)\n",
    "\n",
    "# Calculate the overall z-scores\n",
    "z_scores = zscore(all_supply_values)\n",
    "\n",
    "# Determine the range for non-outlier values based on the z-scores\n",
    "threshold = 3\n",
    "valid_indices = np.where(np.abs(z_scores) <= threshold)[0]\n",
    "valid_values = np.array(all_supply_values)[valid_indices]\n",
    "max_non_outlier = valid_values.max()\n",
    "min_non_outlier = valid_values.min()\n",
    "\n",
    "# Apply the non-outlier range to each _supply field\n",
    "for supply_field in supply_fields:\n",
    "    with arcpy.da.UpdateCursor(fc, supply_field) as cursor:\n",
    "        for row in cursor:\n",
    "            if row[0] > max_non_outlier:\n",
    "                row[0] = max_non_outlier\n",
    "            elif row[0] < min_non_outlier:\n",
    "                row[0] = min_non_outlier\n",
    "            cursor.updateRow(row)\n",
    "\n",
    "# Before the transformation, set _supply to 0 when corresponding _demand is 0\n",
    "for demand_field in demand_fields:\n",
    "    supply_field = demand_field.replace(\"_demand\", \"_supply\")\n",
    "    with arcpy.da.UpdateCursor(fc, [demand_field, supply_field]) as cursor:\n",
    "        for row in cursor:\n",
    "            if row[0] == 0:\n",
    "                row[1] = 0\n",
    "            cursor.updateRow(row)\n",
    "\n",
    "# Use the max_non_outlier as the max_value_all_fields for logarithmic transformation\n",
    "max_value_all_fields = max_non_outlier\n",
    "\n",
    "# Next, transform the _supply fields using logarithms\n",
    "for supply_field in supply_fields:\n",
    "    values = [row[0] for row in arcpy.da.SearchCursor(fc, supply_field)]\n",
    "    # Add 1 to each value, then take its logarithm\n",
    "    transformed_values = np.log(np.array(values) + 1) / np.log(max_value_all_fields + 1)\n",
    "\n",
    "    # Update the field values\n",
    "    with arcpy.da.UpdateCursor(fc, supply_field) as cursor:\n",
    "        for i, row in enumerate(cursor):\n",
    "            row[0] = transformed_values[i]\n",
    "            cursor.updateRow(row)\n",
    "            \n",
    "# Update the 'supplyresult' field with the average of all _supply fields\n",
    "with arcpy.da.UpdateCursor(fc, supply_fields + ['supplyresult']) as cursor:\n",
    "    for row in cursor:\n",
    "        # Calculate average, excluding None values\n",
    "        avg_value = sum(val for val in row[:-1] if val is not None) / len([val for val in row[:-1] if val is not None])\n",
    "        row[-1] = avg_value\n",
    "        cursor.updateRow(row)\n",
    "        \n",
    "# Identify pairs of _demand and _supply fields\n",
    "pair_fields = {}\n",
    "for demand_field in demand_fields:\n",
    "    prefix = demand_field.replace(\"_demand\", \"\")\n",
    "    corresponding_supply_field = prefix + \"_supply\"\n",
    "    if corresponding_supply_field in supply_fields:\n",
    "        pair_fields[demand_field] = corresponding_supply_field\n",
    "\n",
    "# Create a new average field for each pair\n",
    "new_avg_fields = []  # Store the newly created average field names for later use\n",
    "for demand_field, supply_field in pair_fields.items():\n",
    "    avg_field_name = f\"{demand_field.replace('_demand', '')}\"\n",
    "    arcpy.AddField_management(fc, avg_field_name, \"DOUBLE\")\n",
    "    new_avg_fields.append(avg_field_name)\n",
    "\n",
    "    with arcpy.da.UpdateCursor(fc, [demand_field, supply_field, avg_field_name]) as cursor:\n",
    "        for row in cursor:\n",
    "            # Calculate the average, ensuring both fields have values\n",
    "            if row[0] is not None and row[1] is not None:\n",
    "                row[2] = (row[0] + row[1]) / 2\n",
    "                cursor.updateRow(row)\n",
    "\n",
    "# Create an overall average field from the newly generated average fields\n",
    "arcpy.AddField_management(fc, \"average\", \"DOUBLE\")\n",
    "with arcpy.da.UpdateCursor(fc, new_avg_fields + [\"average\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        avg_values = [val for val in row[:-1] if val is not None]\n",
    "        if avg_values:  # Prevent division by zero\n",
    "            total_avg = sum(avg_values) / len(avg_values)\n",
    "            row[-1] = total_avg\n",
    "            cursor.updateRow(row)\n",
    "            \n",
    "def joinpopulation(folder): \n",
    "    arcpy.env.overwriteOutput = True\n",
    "    # Check out any necessary licenses.\n",
    "    arcpy.CheckOutExtension(\"spatial\")\n",
    "    convenience = fr\"{folder}\\output.gdb\\convenience\"\n",
    "    population_tif = arcpy.Raster(fr\"{folder}\\input\\population.tif\")\n",
    "    sedata_shp = fr\"{folder}\\input\\meanprice.shp\"\n",
    "    # Process: Create File Geodatabase (Create File Geodatabase) (management)\n",
    "    analysis_gdb = arcpy.management.CreateFileGDB(out_folder_path=folder.__str__().format(**globals()), out_name=\"analysis\")[0]\n",
    "    # Process: Extract by Mask (Extract by Mask) (sa)\n",
    "    population = fr\"{folder}\\analysis.gdb\\population\"\n",
    "    Extract_by_Mask = population\n",
    "    with arcpy.EnvManager(scratchWorkspace=analysis_gdb):\n",
    "        population = arcpy.sa.ExtractByMask(population_tif, sedata_shp)\n",
    "    # Process: Extract Values to Points (Extract Values to Points) (sa)\n",
    "    convenience_population = fr\"{folder}\\analysis.gdb\\convenience_population\"\n",
    "    arcpy.sa.ExtractValuesToPoints(convenience, population, convenience_population, \"NONE\", \"VALUE_ONLY\")\n",
    "\n",
    "def multiply_fields_by_population_column_and_add_pop(fc):\n",
    "    all_field_names = [f.name for f in arcpy.ListFields(fc)]\n",
    "    arcpy.AlterField_management(fc, 'RASTERVALU', \"population\", \"population\")\n",
    "    all_field_names = [f.name for f in arcpy.ListFields(fc)]\n",
    "    fields_without_special = [f for f in all_field_names if f not in [\"OBJECTID\", \"Shape\", \"population\"]]\n",
    "    all_field_names = [f.name for f in arcpy.ListFields(fc)]\n",
    "    with arcpy.da.UpdateCursor(fc, \"population\") as cursor:\n",
    "        for row in cursor:\n",
    "            if row[0] is None:\n",
    "                row[0] = 0\n",
    "            cursor.updateRow(row)\n",
    "    for field in fields_without_special:\n",
    "        new_field_name = field + \"_pop\"\n",
    "        if new_field_name not in all_field_names:\n",
    "            arcpy.AddField_management(fc, new_field_name, \"DOUBLE\")\n",
    "            all_field_names.append(new_field_name)\n",
    "    fields_to_update = fields_without_special + [\"population\"] + [f + \"_pop\" for f in fields_without_special]\n",
    "    with arcpy.da.UpdateCursor(fc, fields_to_update) as cursor:\n",
    "        for row in cursor:\n",
    "            for i, field in enumerate(fields_without_special):\n",
    "                row_value = float(row[i]) * float(row[len(fields_without_special)])\n",
    "                row[i + len(fields_without_special) + 1] = row_value\n",
    "            cursor.updateRow(row)\n",
    "\n",
    "def spatial_join_and_sum_points_to_polygon(points_fc, polygon_fc):\n",
    "    output_polygon = fr\"{folder}\\output.gdb\\convenience_area\"\n",
    "    all_field_names = [f.name for f in arcpy.ListFields(points_fc)]\n",
    "    fields_with_pop = [f for f in all_field_names if \"pop\" in f]\n",
    "    field_mappings = arcpy.FieldMappings()\n",
    "    for field in fields_with_pop:\n",
    "        fm = arcpy.FieldMap()\n",
    "        fm.addInputField(points_fc, field)\n",
    "        f_out = fm.outputField\n",
    "        f_out.name = field\n",
    "        fm.outputField = f_out\n",
    "        fm.mergeRule = 'Sum'\n",
    "        field_mappings.addFieldMap(fm)\n",
    "    arcpy.analysis.SpatialJoin(target_features=polygon_fc, \n",
    "                               join_features=points_fc, \n",
    "                               out_feature_class=output_polygon, \n",
    "                               join_type=\"KEEP_COMMON\", \n",
    "                               field_mapping=field_mappings, \n",
    "                               match_option=\"INTERSECT\")\n",
    "\n",
    "def divide_fields_by_population_and_rename(output_polygon):\n",
    "    all_field_names = [f.name for f in arcpy.ListFields(output_polygon)]\n",
    "    fields_with_pop = [f for f in all_field_names if \"_pop\" in f]\n",
    "    if 'population' in all_field_names:\n",
    "        for field in fields_with_pop:\n",
    "            new_field_name = field.replace(\"_pop\", \"\")\n",
    "            arcpy.AddField_management(output_polygon, new_field_name, \"DOUBLE\")\n",
    "            with arcpy.da.UpdateCursor(output_polygon, [field, 'population', new_field_name]) as cursor:\n",
    "                for row in cursor:\n",
    "                    if row[1] != 0:\n",
    "                        row[2] = row[0] / row[1]\n",
    "                    else:\n",
    "                        row[2] = None\n",
    "                    cursor.updateRow(row)\n",
    "            arcpy.DeleteField_management(output_polygon, field)\n",
    "    fields_to_delete = ['Join_Count', 'TARGET_FID']\n",
    "    for field in fields_to_delete:\n",
    "        if field in all_field_names:\n",
    "            arcpy.DeleteField_management(output_polygon, field)\n",
    "\n",
    "def spatial_join_meanprice_to_convenience_area():\n",
    "    target_features = fr\"{folder}\\output.gdb\\convenience_area\"\n",
    "    join_features = fr\"{folder}\\input\\meanprice.shp\"\n",
    "    output_features = fr\"{folder}\\output.gdb\\convenience_area_update\"\n",
    "    field_mappings = arcpy.FieldMappings()\n",
    "    field_mappings.addTable(target_features)\n",
    "    for field in [\"LSOA21CD\", \"meanprice\"]:\n",
    "        fm = arcpy.FieldMap()\n",
    "        fm.addInputField(join_features, field)\n",
    "        field_mappings.addFieldMap(fm)\n",
    "    arcpy.analysis.SpatialJoin(target_features=target_features, \n",
    "                               join_features=join_features, \n",
    "                               out_feature_class=output_features, \n",
    "                               join_type=\"KEEP_ALL\", \n",
    "                               field_mapping=field_mappings, \n",
    "                               match_option=\"ARE_IDENTICAL_TO\")\n",
    "    existing_fields = [field.name for field in arcpy.ListFields(output_features)]\n",
    "    unwanted_fields = ['Join_Count', 'TARGET_FID']\n",
    "    for field in unwanted_fields:\n",
    "        if field in existing_fields:\n",
    "            arcpy.DeleteField_management(output_features, field)\n",
    "    arcpy.management.Delete(target_features)\n",
    "    arcpy.management.Rename(output_features, target_features)\n",
    "\n",
    "\n",
    "### run\n",
    "with arcpy.EnvManager(outputCoordinateSystem=\"PROJCS[\\\"British_National_Grid\\\",GEOGCS[\\\"GCS_OSGB_1936\\\",DATUM[\\\"D_OSGB_1936\\\",SPHEROID[\\\"Airy_1830\\\",6377563.396,299.3249646]],PRIMEM[\\\"Greenwich\\\",0.0],UNIT[\\\"Degree\\\",0.0174532925199433]],PROJECTION[\\\"Transverse_Mercator\\\"],PARAMETER[\\\"False_Easting\\\",400000.0],PARAMETER[\\\"False_Northing\\\",-100000.0],PARAMETER[\\\"Central_Meridian\\\",-2.0],PARAMETER[\\\"Scale_Factor\\\",0.9996012717],PARAMETER[\\\"Latitude_Of_Origin\\\",49.0],UNIT[\\\"Meter\\\",1.0]]\", scratchWorkspace=folder, workspace=folder):\n",
    "    polygon_fc = fr\"{folder}\\input\\meanprice.shp\"\n",
    "    joinpopulation(folder)\n",
    "    multiply_fields_by_population_column_and_add_pop(fr\"{folder}\\analysis.gdb\\convenience_population\")\n",
    "    spatial_join_and_sum_points_to_polygon(fr\"{folder}\\analysis.gdb\\convenience_population\", polygon_fc)\n",
    "    divide_fields_by_population_and_rename(fr\"{folder}\\output.gdb\\convenience_area\")\n",
    "    spatial_join_meanprice_to_convenience_area()\n",
    "    arcpy.SetParameter(1, True)\n",
    "    arcpy.AddMessage(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### censusandcluster.py\n",
    "\n",
    "***Parameters***\n",
    "\n",
    "|Name|Data Type|Type|Direction|\n",
    "|---|---|---|---|\n",
    "|folder|Folder|Required|Input|\n",
    "|success|Boolean|Derived|Output|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import arcpy\n",
    "\n",
    "\n",
    "### input parameter\n",
    "folder=arcpy.GetParameterAsText(0)\n",
    "\n",
    "\n",
    "### environment\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.workspace = fr\"{folder}\\input\\census\"\n",
    "\n",
    "\n",
    "### functions\n",
    "avg_age_raw = pd.read_csv(fr\"{folder}\\input\\census\\RM200-Sex-By-Single-Year-Of-Age-(Detailed)-2021-lsoa-ONS.csv\")\n",
    "grouped = avg_age_raw.groupby(['Lower layer Super Output Areas Code', 'Age (91 categories) Code']).agg({'Observation': 'sum'}).reset_index()\n",
    "grouped['Weighted Age'] = grouped['Age (91 categories) Code'] * grouped['Observation']\n",
    "avg_age = grouped.groupby('Lower layer Super Output Areas Code').apply(lambda x: x['Weighted Age'].sum() / x['Observation'].sum()).reset_index()\n",
    "avg_age.columns = ['LSOA_code', 'age']\n",
    "print(avg_age)\n",
    "avg_age.to_csv(\"age.csv\", index=False)\n",
    "\n",
    "percentage_non_uk_raw = pd.read_csv(fr\"{folder}\\input\\census\\TS004-Country-Of-Birth-2021-lsoa-ONS.csv\")\n",
    "non_uk_population = percentage_non_uk_raw[percentage_non_uk_raw['Country of birth (12 categories)'] != 'Europe: United Kingdom'].groupby('Lower Layer Super Output Areas Code')['Observation'].sum()\n",
    "total_population = percentage_non_uk_raw.groupby('Lower Layer Super Output Areas Code')['Observation'].sum()\n",
    "percentage_non_uk = (non_uk_population / total_population).reset_index()\n",
    "percentage_non_uk.columns = ['LSOA_code', 'nonlocal']\n",
    "print(percentage_non_uk)\n",
    "percentage_non_uk.to_csv(\"nonlocal.csv\", index=False)\n",
    "\n",
    "percentage_less_than_5_years_raw = pd.read_csv(fr\"{folder}\\input\\census\\TS016-Length-Of-Residence-2021-lsoa-ONS.csv\")\n",
    "less_than_5_years = percentage_less_than_5_years_raw[percentage_less_than_5_years_raw['Length of residence in the UK (6 categories)'].isin(['2 years or more, but less than 5 years', 'Less than 2 years'])]\n",
    "population_less_than_5_years = less_than_5_years.groupby('Lower layer Super Output Areas Code')['Observation'].sum()\n",
    "total_population = percentage_less_than_5_years_raw.groupby('Lower layer Super Output Areas Code')['Observation'].sum()\n",
    "percentage_less_than_5_years = (population_less_than_5_years / total_population).reset_index()\n",
    "percentage_less_than_5_years.columns = ['LSOA_code', 'mobility']\n",
    "print(percentage_less_than_5_years)\n",
    "percentage_less_than_5_years.to_csv(\"mobility.csv\", index=False)\n",
    "\n",
    "average_household_size_raw = pd.read_csv(fr\"{folder}\\input\\census\\TS017-Household-Size-2021-lsoa-ONS.csv\")\n",
    "average_household_size_raw['Total People for Household Size'] = average_household_size_raw['Household size (9 categories) Code'] * average_household_size_raw['Observation']\n",
    "total_people_per_area = average_household_size_raw.groupby('Lower layer Super Output Areas Code')['Total People for Household Size'].sum()\n",
    "total_households_per_area = average_household_size_raw.groupby('Lower layer Super Output Areas Code')['Observation'].sum()\n",
    "average_household_size = (total_people_per_area / total_households_per_area).reset_index()\n",
    "average_household_size.columns = ['LSOA_code', 'household']\n",
    "print(average_household_size)\n",
    "average_household_size.to_csv(\"household.csv\", index=False)\n",
    "\n",
    "diversity_index_raw = pd.read_csv(fr\"{folder}\\input\\census\\TS021-Ethnic-Group-2021-lsoa-ONS.csv\")\n",
    "total_population_per_area = diversity_index_raw.groupby('Lower layer Super Output Areas Code')['Observation'].sum()\n",
    "def shannon_diversity(group):\n",
    "    proportions = group['Observation'] / total_population_per_area[group.name]\n",
    "    return -np.sum(proportions * np.log(proportions))\n",
    "diversity_index = diversity_index_raw.groupby('Lower layer Super Output Areas Code').apply(shannon_diversity).reset_index()\n",
    "diversity_index.columns = ['LSOA_code', 'ethnic']\n",
    "print(diversity_index)\n",
    "diversity_index.to_csv(\"ethnic.csv\", index=False)\n",
    "\n",
    "faithful_proportion_raw = pd.read_csv(fr\"{folder}\\input\\census\\TS030-Religion-2021-lsoa-ONS.csv\")\n",
    "total_population_per_area = faithful_proportion_raw.groupby('Lower layer Super Output Areas Code')['Observation'].sum()\n",
    "faithful_proportion_raw_faithful = faithful_proportion_raw[~faithful_proportion_raw['Religion (10 categories) Code'].isin([1])]\n",
    "faithful_population_per_area = faithful_proportion_raw_faithful.groupby('Lower layer Super Output Areas Code')['Observation'].sum()\n",
    "faithful_proportion = (faithful_population_per_area / total_population_per_area).reset_index()\n",
    "faithful_proportion.columns = ['LSOA_code', 'religion']\n",
    "print(faithful_proportion)\n",
    "faithful_proportion.to_csv(\"religion.csv\", index=False)\n",
    "\n",
    "car_ownership_proportion_raw = pd.read_csv(fr\"{folder}\\input\\census\\TS045-Car-Or-Van-Availability-2021-lsoa-ONS.csv\")\n",
    "car_ownership_proportion_raw_cars = car_ownership_proportion_raw[~car_ownership_proportion_raw['Car or van availability (5 categories) Code'].isin([-8, 0])]\n",
    "car_ownership_per_area = car_ownership_proportion_raw_cars.groupby('Lower layer Super Output Areas Code')['Observation'].sum()\n",
    "total_households_per_area = car_ownership_proportion_raw.groupby('Lower layer Super Output Areas Code')['Observation'].sum()\n",
    "car_ownership_proportion = (car_ownership_per_area / total_households_per_area).reset_index()\n",
    "car_ownership_proportion.columns = ['LSOA_code', 'car']\n",
    "print(car_ownership_proportion)\n",
    "car_ownership_proportion.to_csv(\"car.csv\", index=False)\n",
    "\n",
    "average_rooms_per_area_raw = pd.read_csv(fr\"{folder}\\input\\census\\TS051-Number-Of-Rooms-2021-lsoa-ONS.csv\")\n",
    "average_rooms_per_area_raw['weighted_rooms'] = average_rooms_per_area_raw['Number of rooms (Valuation Office Agency) (9 categories) Code'] * average_rooms_per_area_raw['Observation']\n",
    "total_houses_per_area = average_rooms_per_area_raw.groupby('Lower layer Super Output Areas Code')['Observation'].sum()\n",
    "total_weighted_rooms_per_area = average_rooms_per_area_raw.groupby('Lower layer Super Output Areas Code')['weighted_rooms'].sum()\n",
    "average_rooms_per_area = (total_weighted_rooms_per_area / total_houses_per_area).reset_index()\n",
    "average_rooms_per_area.columns = ['LSOA_code', 'housing']\n",
    "print(average_rooms_per_area)\n",
    "average_rooms_per_area.to_csv(\"housing.csv\", index=False)\n",
    "\n",
    "average_distance_per_area_raw = pd.read_csv(fr\"{folder}\\input\\census\\TS058-Distance-Travelled-To-Work-2021-lsoa-ONS.csv\")\n",
    "distance_means = {\n",
    "    \"Less than 2km\": 1,\n",
    "    \"2km to less than 5km\": 3.5,\n",
    "    \"5km to less than 10km\": 7.5,\n",
    "    \"10km to less than 20km\": 15,\n",
    "    \"20km to less than 30km\": 25,\n",
    "    \"30km to less than 40km\": 35,\n",
    "    \"40km to less than 60km\": 50,\n",
    "    \"60km and over\": 70,\n",
    "    \"Works mainly from home\": 0,\n",
    "}\n",
    "average_distance_per_area_raw['mean_distance'] = average_distance_per_area_raw['Distance travelled to work (11 categories)'].map(distance_means)\n",
    "excluded_categories = [\"Does not apply\", \"Works mainly at an offshore installation, in no fixed place, or outside the UK\"]\n",
    "average_distance_per_area_raw = average_distance_per_area_raw[~average_distance_per_area_raw['Distance travelled to work (11 categories)'].isin(excluded_categories)]\n",
    "average_distance_per_area_raw['weighted_distance'] = average_distance_per_area_raw['mean_distance'] * average_distance_per_area_raw['Observation']\n",
    "total_observations_per_area = average_distance_per_area_raw.groupby('Lower Layer Super Output Areas Code')['Observation'].sum()\n",
    "total_weighted_distance_per_area = average_distance_per_area_raw.groupby('Lower Layer Super Output Areas Code')['weighted_distance'].sum()\n",
    "average_distance_per_area = (total_weighted_distance_per_area / total_observations_per_area).reset_index()\n",
    "average_distance_per_area.columns = ['LSOA_code', 'commuting']\n",
    "print(average_distance_per_area)\n",
    "average_distance_per_area.to_csv(\"commuting.csv\", index=False)\n",
    "\n",
    "employment_ratio_raw = pd.read_csv(fr\"{folder}\\input\\census\\TS066-Economic-Activity-Status-2021-lsoa-ONS.csv\")\n",
    "employment_ratio_raw['is_in_employment'] = employment_ratio_raw['Economic activity status (20 categories)'].str.contains('In employment').astype(int)\n",
    "employment_ratio_raw['employed_count'] = employment_ratio_raw['is_in_employment'] * employment_ratio_raw['Observation']\n",
    "agg_employment_ratio_raw = employment_ratio_raw.groupby('Lower Layer Super Output Areas Code').agg({\n",
    "    'employed_count': 'sum',\n",
    "    'Observation': 'sum'\n",
    "}).reset_index()\n",
    "agg_employment_ratio_raw['employment_ratio'] = agg_employment_ratio_raw['employed_count'] / agg_employment_ratio_raw['Observation']\n",
    "result_employment_ratio_raw = agg_employment_ratio_raw[['Lower Layer Super Output Areas Code', 'employment_ratio']]\n",
    "result_employment_ratio_raw.columns = ['LSOA_code', 'work']\n",
    "print(result_employment_ratio_raw)\n",
    "result_employment_ratio_raw.to_csv(\"work.csv\", index=False)\n",
    "\n",
    "files = os.listdir()\n",
    "selected_files = [file for file in files if not any(char.isdigit() for char in file) and file.endswith('.csv')]\n",
    "dfs = []\n",
    "for file in selected_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "merged_df = dfs[0]\n",
    "for df in dfs[1:]:\n",
    "    merged_df = pd.merge(merged_df, df, on=\"LSOA_code\", how=\"outer\")\n",
    "merged_df.to_csv(fr\"{folder}\\input\\censusdata.csv\", index=False)\n",
    "\n",
    "arcpy.env.workspace = folder\n",
    "\n",
    "def cluster(folder):\n",
    "    convenience_area = fr\"{folder}\\output.gdb\\convenience_area\"\n",
    "    censusdata_csv = fr\"{folder}\\input\\censusdata.csv\"\n",
    "    arcpy.management.CreateFileGDB(folder, \"others.gdb\")\n",
    "\n",
    "    # Process: Feature Class To Feature Class (Feature Class To Feature Class) (conversion)\n",
    "    analysisunit = arcpy.conversion.FeatureClassToFeatureClass(\n",
    "        in_features=convenience_area, \n",
    "        out_path=fr\"{folder}\\others.gdb\", \n",
    "        out_name=\"analysisunit\"\n",
    "    )[0]\n",
    "    # Process: Join Field (Join Field) (management)\n",
    "    analysisunit_2_ = arcpy.management.JoinField(in_data=analysisunit, in_field=\"LSOA21CD\", join_table=censusdata_csv, join_field=\"LSOA_code\")[0]\n",
    "    # Process: Spatially Constrained Multivariate Clustering (Spatially Constrained Multivariate Clustering) (stats)\n",
    "    analysisunit_SCMC = fr\"{folder}\\output.gdb\\analysisunit_SCMC\"\n",
    "    arcpy.stats.SpatiallyConstrainedMultivariateClustering(in_features=analysisunit_2_, output_features=analysisunit_SCMC, analysis_fields=[\"age\", \"car\", \"commuting\", \"ethnic\", \"household\", \"housing\", \"mobility\", \"nonlocal\", \"religion\", \"work\"], number_of_clusters=20, spatial_constraints=\"CONTIGUITY_EDGES_CORNERS\", number_of_permutations=200, output_table=\"\")\n",
    "\n",
    "### run\n",
    "with arcpy.EnvManager(outputCoordinateSystem=\"PROJCS[\\\"British_National_Grid\\\",GEOGCS[\\\"GCS_OSGB_1936\\\",DATUM[\\\"D_OSGB_1936\\\",SPHEROID[\\\"Airy_1830\\\",6377563.396,299.3249646]],PRIMEM[\\\"Greenwich\\\",0.0],UNIT[\\\"Degree\\\",0.0174532925199433]],PROJECTION[\\\"Transverse_Mercator\\\"],PARAMETER[\\\"False_Easting\\\",400000.0],PARAMETER[\\\"False_Northing\\\",-100000.0],PARAMETER[\\\"Central_Meridian\\\",-2.0],PARAMETER[\\\"Scale_Factor\\\",0.9996012717],PARAMETER[\\\"Latitude_Of_Origin\\\",49.0],UNIT[\\\"Meter\\\",1.0]]\", scratchWorkspace=\"C:\\\\Users\\\\xianl\\\\Documents\\\\ArcGIS\\\\Projects\\\\CASA0010\\\\CASA0010.gdb\", workspace=\"C:\\\\Users\\\\xianl\\\\Documents\\\\ArcGIS\\\\Projects\\\\CASA0010\\\\CASA0010.gdb\"):\n",
    "    cluster(folder)\n",
    "    arcpy.SetParameter(1, True)\n",
    "    arcpy.AddMessage(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In progress for the auto weighted calculation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
